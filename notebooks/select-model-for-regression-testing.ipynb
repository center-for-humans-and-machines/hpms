{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f895500",
   "metadata": {},
   "source": [
    "# Select model for regression testing\n",
    "\n",
    "Conduct quantitative evaluation of different models on generating realistic simulated conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1eb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes into one. Iterate through each file and append the data\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from hpms.loading.constants import DATA_DIR\n",
    "\n",
    "DATASET_DIR_2: Path = DATA_DIR / Path(\"paper/round-2-generation\")\n",
    "\n",
    "df_list = []\n",
    "# Iterate through all the dataset-round-*.json files\n",
    "for model_file in DATASET_DIR_2.glob(\"dataset-round-*.json\"):\n",
    "    # Read the JSON file into a Polars DataFrame\n",
    "    df = pl.read_json(model_file)\n",
    "    # Drop the cost_in_usd column if it exists\n",
    "    if \"cost_in_usd\" in df.columns:\n",
    "        df = df.drop(\"cost_in_usd\")\n",
    "\n",
    "    # Append to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "merged_df_2 = pl.concat(df_list, how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414d7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "\n",
    "def extract_unique_content_by_model(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract unique content values from conversation column grouped by model.\n",
    "\n",
    "    Args:\n",
    "        df: Input dataframe with conversation data\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Dataframe with new content_set column containing unique content per model\n",
    "    \"\"\"\n",
    "    # Extract all content from conversations and create a mapping by model\n",
    "    content_by_model = (\n",
    "        df.with_columns(\n",
    "            # Extract content from each conversation message\n",
    "            pl.col(\"conversation\")\n",
    "            .list.eval(pl.element().struct.field(\"content\"))\n",
    "            .alias(\"all_content\")\n",
    "        )\n",
    "        .group_by(\"model\")\n",
    "        .agg(\n",
    "            # Flatten all content lists and get unique values\n",
    "            pl.col(\"all_content\").list.explode().unique().alias(\"unique_content_set\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Join back to original dataframe\n",
    "    result = (\n",
    "        df.join(\n",
    "            content_by_model.select([\"model\", \"unique_content_set\"]),\n",
    "            on=\"model\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .with_columns(pl.col(\"unique_content_set\").alias(\"content_set\"))\n",
    "        .drop(\"unique_content_set\")\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669cc4a5",
   "metadata": {},
   "source": [
    "## Create table of unique messages by model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd6fad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>content_set</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>1000</td><td>100</td></tr><tr><td>&quot;gpt-4.1-nano-2025-04-14&quot;</td><td>1000</td><td>100</td></tr><tr><td>&quot;gpt-5-nano-2025-08-07&quot;</td><td>999</td><td>100</td></tr><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>993</td><td>100</td></tr><tr><td>&quot;gemini-2.5-flash&quot;</td><td>979</td><td>100</td></tr><tr><td>&quot;gemini-2.5-flash-lite&quot;</td><td>956</td><td>100</td></tr><tr><td>&quot;gemini-2.0-flash&quot;</td><td>944</td><td>100</td></tr><tr><td>&quot;meta-llama/Meta-Llama-3.1-70B-…</td><td>941</td><td>100</td></tr><tr><td>&quot;gemini-2.0-flash-lite&quot;</td><td>936</td><td>100</td></tr><tr><td>&quot;meta-llama/Llama-3.3-70B-Instr…</td><td>781</td><td>100</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌─────────────────────────────────┬─────────────┬───────┐\n",
       "│ model                           ┆ content_set ┆ count │\n",
       "│ ---                             ┆ ---         ┆ ---   │\n",
       "│ str                             ┆ i64         ┆ u32   │\n",
       "╞═════════════════════════════════╪═════════════╪═══════╡\n",
       "│ gpt-4o-mini-2024-07-18          ┆ 1000        ┆ 100   │\n",
       "│ gpt-4.1-nano-2025-04-14         ┆ 1000        ┆ 100   │\n",
       "│ gpt-5-nano-2025-08-07           ┆ 999         ┆ 100   │\n",
       "│ gpt-4o-2024-08-06               ┆ 993         ┆ 100   │\n",
       "│ gemini-2.5-flash                ┆ 979         ┆ 100   │\n",
       "│ gemini-2.5-flash-lite           ┆ 956         ┆ 100   │\n",
       "│ gemini-2.0-flash                ┆ 944         ┆ 100   │\n",
       "│ meta-llama/Meta-Llama-3.1-70B-… ┆ 941         ┆ 100   │\n",
       "│ gemini-2.0-flash-lite           ┆ 936         ┆ 100   │\n",
       "│ meta-llama/Llama-3.3-70B-Instr… ┆ 781         ┆ 100   │\n",
       "└─────────────────────────────────┴─────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_unique_content_by_model(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze unique content count by model and return summary statistics.\n",
    "\n",
    "    Args:\n",
    "        df: Input dataframe with conversation data\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Summary table with model, unique content count, and frequency\n",
    "    \"\"\"\n",
    "    # Extract unique content by model\n",
    "    df_with_content = extract_unique_content_by_model(df)\n",
    "\n",
    "    # Convert content_set to count of unique messages\n",
    "    df_with_counts = df_with_content.with_columns(\n",
    "        pl.col(\"content_set\").map_elements(lambda x: len(x), return_dtype=pl.Int64)\n",
    "    )\n",
    "\n",
    "    # Group by model and content count to get summary statistics\n",
    "    summary = (\n",
    "        df_with_counts.group_by([\"model\", \"content_set\"])\n",
    "        .agg(pl.len().alias(\"count\"))\n",
    "        .sort(\"content_set\", descending=True)\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Usage\n",
    "summary_df_2 = analyze_unique_content_by_model(merged_df_2)\n",
    "summary_df_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
